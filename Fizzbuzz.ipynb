{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fizz Buzz in Tensorflow!\n",
    "# see http://joelgrus.com/2016/05/23/fizz-buzz-in-tensorflow/\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_DIGITS = 32\n",
    "\n",
    "# Represent each input by an array of its binary digits.\n",
    "def binary_encode(i, num_digits):\n",
    "    return np.array([i >> d & 1 for d in range(num_digits)])\n",
    "\n",
    "# One-hot encode the desired outputs: [number, \"fizz\", \"buzz\", \"fizzbuzz\"]\n",
    "def fizz_buzz_encode(i):\n",
    "    if   i % 15 == 0: return np.array([0, 0, 0, 1])\n",
    "    elif i % 5  == 0: return np.array([0, 0, 1, 0])\n",
    "    elif i % 3  == 0: return np.array([0, 1, 0, 0])\n",
    "    else:             return np.array([1, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fizz_buzz_encode(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Our goal is to produce fizzbuzz for the numbers 1 to 100. So it would be\n",
    "# unfair to include these in our training data. Accordingly, the training data\n",
    "# corresponds to the numbers 101 to (2 ** NUM_DIGITS - 1).\n",
    "trX = np.array([binary_encode(i, NUM_DIGITS) for i in range(101, 2 ** NUM_DIGITS)])\n",
    "trY = np.array([fizz_buzz_encode(i)          for i in range(101, 2 ** NUM_DIGITS)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We'll want to randomly initialize weights.\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our model is a standard 1-hidden-layer multi-layer-perceptron with ReLU\n",
    "# activation. The softmax (which turns arbitrary real-valued outputs into\n",
    "# probabilities) gets applied in the cost function.\n",
    "def model(X, w_h, w_o):\n",
    "    h = tf.nn.relu(tf.matmul(X, w_h))\n",
    "    return tf.matmul(h, w_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our variables. The input has width NUM_DIGITS, and the output has width 4.\n",
    "X = tf.placeholder(\"float\", [None, NUM_DIGITS])\n",
    "Y = tf.placeholder(\"float\", [None, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How many units in the hidden layer.\n",
    "NUM_HIDDEN = 100\n",
    "\n",
    "# Initialize the weights.\n",
    "w_h = init_weights([NUM_DIGITS, NUM_HIDDEN])\n",
    "w_o = init_weights([NUM_HIDDEN, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict y given x using the model.\n",
    "py_x = model(X, w_h, w_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We'll train our model by minimizing a cost function.\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(py_x, Y))\n",
    "train_op = tf.train.GradientDescentOptimizer(0.05).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And we'll make predictions by choosing the largest output.\n",
    "predict_op = tf.argmax(py_x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finally, we need a way to turn a prediction (and an original number)\n",
    "# into a fizz buzz output\n",
    "def fizz_buzz(i, prediction):\n",
    "    return [str(i), \"fizz\", \"buzz\", \"fizzbuzz\"][prediction]\n",
    "\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "    for epoch in range(10000):\n",
    "        # Shuffle the data before each training iteration.\n",
    "        p = np.random.permutation(range(len(trX)))\n",
    "        trX, trY = trX[p], trY[p]\n",
    "\n",
    "        # Train in batches of 128 inputs.\n",
    "        for start in range(0, len(trX), BATCH_SIZE):\n",
    "            end = start + BATCH_SIZE\n",
    "            sess.run(train_op, feed_dict={X: trX[start:end], Y: trY[start:end]})\n",
    "\n",
    "        # And print the current accuracy on the training data.\n",
    "        print(epoch, np.mean(np.argmax(trY, axis=1) ==\n",
    "                             sess.run(predict_op, feed_dict={X: trX, Y: trY})))\n",
    "\n",
    "    # And now for some fizz buzz\n",
    "    numbers = np.arange(1, 101)\n",
    "    teX = np.transpose(binary_encode(numbers, NUM_DIGITS))\n",
    "    teY = sess.run(predict_op, feed_dict={X: teX})\n",
    "    output = np.vectorize(fizz_buzz)(numbers, teY)\n",
    "\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
