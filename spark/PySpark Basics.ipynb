{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import pow\n",
    "from scipy.constants import c \n",
    "\n",
    "def E(m):\n",
    "    return m * pow(c,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "E(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact, widgets\n",
    "interact(E, m=widgets.IntSlider(min=-0,max=30,step=1,value=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fun facts:\n",
    "    * $E=mc^2$\n",
    "        ![](http://cf.chucklesnetwork.com/items/1/1/9/3/7/0/original/im-sorry-i-cant-hear-you-over-how-awesome-science-is.jpg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark info and help\n",
    "* Guides:\n",
    "    * [Spark SQL, DataFrames and Datasets Guide](http://spark.apache.org/docs/latest/sql-programming-guide.html)\n",
    "    * [Machine Learning Library (MLlib) Guide](http://spark.apache.org/docs/latest/ml-guide.html)\n",
    "* API:\n",
    "    * [pyspark.sql](https://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html)\n",
    "    * [pyspark.ml](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html)\n",
    "* Stack Overflow\n",
    "    * ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "events = (sqlContext.read.csv('hdfs://hdfs-mesos/data.csv', sep=';', inferSchema=True)\n",
    "    .withColumnRenamed('_c0', 'time')\n",
    "    .withColumnRenamed('_c1', 'browser')\n",
    "    .withColumnRenamed('_c2', 'os')\n",
    "    .withColumnRenamed('_c3', 'deviceType')\n",
    "    .withColumnRenamed('_c4', 'country')\n",
    "    .withColumnRenamed('_c5', 'city')\n",
    "    .withColumnRenamed('_c6', 'userId')\n",
    "    .cache())\n",
    "\n",
    "events.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "events.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering and counting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as fun\n",
    "\n",
    "desktop_events = events.filter(fun.col('deviceType') == 'Desktop').count()\n",
    "\n",
    "desktop_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group-by aggregations - counting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device_events = events.groupBy('deviceType').count()\n",
    "\n",
    "sorted_device_events = device_events.orderBy(fun.col('count').desc())\n",
    "\n",
    "sorted_device_events.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group-by aggregations - cardinality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device_uniques = events.groupBy('deviceType').agg(fun.countDistinct('userId').alias('uniqueUsers'))\n",
    "\n",
    "device_uniques.show()                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Spark DF to Pandas DF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "device_uniques_pdf = device_uniques.toPandas().set_index('deviceType')\n",
    "\n",
    "device_uniques_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting data – Pie charts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "device_uniques_pdf.plot.pie(subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting data – histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "events_per_user = events.groupBy(\"userId\").count()\n",
    "\n",
    "events_per_user.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "histogram = events_per_user.rdd.values().histogram(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def draw_hist(rdd_histogram_data):\n",
    "  \"\"\"Stolen from the Internets : Given an RDD.histogram, plot a pyplot histogram\"\"\"\n",
    "  heights = np.array(rdd_histogram_data[1])\n",
    "  full_bins = rdd_histogram_data[0]\n",
    "  mid_point_bins = full_bins[:-1]\n",
    "  widths = [abs(i - j) for i, j in zip(full_bins[:-1], full_bins[1:])]\n",
    "  bar = plt.bar(mid_point_bins, heights, width=widths, log=True)\n",
    "  return bar\n",
    "\n",
    "draw_hist(histogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Awesomeness - Pivoting with Pandas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os_and_browser_count = events.groupBy(\"os\", \"browser\").count().toPandas()\n",
    "\n",
    "os_and_browser_count['os'] = os_and_browser_count['os'].fillna('unknown')\n",
    "\n",
    "os_and_browser_count.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = os_and_browser_count.pivot(index='os', columns='browser', values='count').fillna(0)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.pcolor(df)\n",
    "plt.set_cmap('Reds')\n",
    "plt.yticks(np.arange(0.5, len(df.index), 1), df.index)\n",
    "plt.xticks(np.arange(0.5, len(df.columns), 1), df.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "events = events.withColumn(\"date\", events[\"time\"].cast(\"timestamp\"))\n",
    "events.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Converting values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "toTimeString = fun.UserDefinedFunction(\n",
    "    lambda x: datetime.datetime.fromtimestamp(x).strftime('%Y-%m-%d %H%:M:%S'),\n",
    "    fun.StringType())\n",
    "\n",
    "dates = events.select(toTimeString(fun.col(\"time\")).alias(\"date\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "events.select(fun.from_unixtime(fun.col(\"time\")).alias(\"date\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "events = events.withColumn(\"date\", fun.col(\"time\").cast(\"timestamp\"))\n",
    "events.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More magic pandas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdf = events.groupBy(\"date\").count().toPandas().set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdf.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdf.plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more plotting examples see [pandas-docs](http://pandas.pydata.org/pandas-docs/version/0.19.1/visualization.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "events.createOrReplaceTempView(\"events\")\n",
    "spark.sql(\"SELECT os, count(*) as events FROM events \\\n",
    "          WHERE browser = 'Firefox' AND deviceType = 'Desktop' \\\n",
    "          GROUP BY os ORDER BY events DESC\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
